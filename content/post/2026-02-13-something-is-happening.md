---
title: "Response to \"Something Big is Happening\""
date: "2026-02-13T09:00:00-05:00"
url: "posts/response-to-something-big-is-happening"
categories:
- Reflection
- ai
tags:
- ai
- claude
- chatgpt
- psychology
- saaspocalypse
author: "Chris"
showToc: false
TocOpen: false
draft: false
hidemeta: false
comments: false
description: "Something big IS happening, but on what timescale?"
disableHLJS: true # to disable highlightjs
disableShare: false
hideSummary: false
searchHidden: false
ShowReadingTime: true
ShowBreadCrumbs: true
ShowPostNavLinks: true
ShowWordCount: true
ShowRssButtonInSectionTermList: true
UseHugoToc: true
---

## Something Big is Coming
An article by
[@mattshumer_](https://x.com/mattshumer_/status/2021256989876109403) is making
the rounds on X. As of this writing, it's been viewed 80 million times. It's a
forewarning of the seismic changes that AI disruption will bring to the global
economy and society.

It's hard to argue against the fact that AI is changing the world as we know it.
(I've increasingly used ChatGPT and Claude for producing work product and the
results can be *astounding*. It feels like cheating. But is it? I'll come back to that later.)

What I want to explore in this post is what I view as overlooked in either the "Something Big is Happening" scenario or its rebuttals: the immediate effect on society.

## Reasonable Rebuttal - "The Seen and the Unseen"
In ["The Seen and the
Unseen"](https://x.com/cboyack/status/2021647373571862952), @cboyack references
19th century French Economist Frédéric Bastiat. Bastiat essentially states
technological disruption feels scary because humans can't predict the future or the value added by the disruptive technology. 

@cboyack presents the argument that, yes, AI advancement is happening rapidly and yes it will have an effect, but that's alright because in the future AI will have created value and new industries that we aren't able to comprehend right now.

@cboyack:
> When you read a headline that says "AI will replace 40% of jobs," your brain does something very specific: it imagines 40% of current workers losing their current jobs and sitting idle. It does not (it cannot) simultaneously imagine the new roles, new industries, and new forms of value that will be created. Because those things don't exist yet. They're unseen.

Yes, actually, I can imagine *that* new roles, industries, and forms of value will be created by such an obviously powerful technology. *But on what timeline*?

@cboyack again (emphasis mine): 
> But the technology didn't die with him. His brother brought the knitting frames back to England. The machines spread. ***And over the next two centuries***, that very same textile industry—the one Elizabeth tried to protect by freezing it in place—became the engine of the Industrial Revolution.

Two centuries is a helluva long time to adapt to a new technology. We are seeing major innovations in the AI space every few *weeks*, and major companies, like Amazon, have cited "AI efficiency gains" as recently as last October - note that this was before Claude Opus 4.6 and ChatGPT Codex 5.3 were released *just last week*. [According to CNBC](https://www.cnbc.com/2025/12/21/ai-job-cuts-amazon-microsoft-and-more-cite-ai-for-2025-layoffs.html), MIT released a study in November 2025 showing AI can "do the job of 11.7% of the U.S. labor market and save as much as $1.2 trillion in wages."

Just to level set, ChatGPT was released to the public in November of 2022. The most competent models from Anthropic and OpenAI were released just over a week ago. Within 3.3 years, a technology is capable of replacing 11.7% of the U.S. labor market and saving as much as $1.2 trillion in wages. And that technology is getting better every few months. 

Oh, and ChatGPT Codex 5.3's standout feature was [its ability to help build itself.](https://openai.com/index/introducing-gpt-5-3-codex/#:~:text=GPT%E2%80%915%2E3%E2%80%91Codex%20is%20our%20first%20model%20that%20was%20instrumental%20in%20creating%20itself%2E)

I don't think the knitting frame helped to build itself. The Internet, the closest technological analogue I can think of to AI, enjoyed massive, rapid widespread adoption and build out because the world clearly saw its value, but it, too, did not build itself.

## Reasonable Rebuttal - "Love it if we made it"

[M.G. Siegler writes](https://spyglass.org/ai-future-work/):
> But the disruption of the day-to-day code writing seems unlikely to play out as seamlessly across other industries. As many have noted in the past, AI is uniquely suited to write code because of the way LLMs work. Other jobs and just jobs-to-be-done will likely require other variants of AI that perhaps aren't as probabilistic.

I think this is a key insight: other industries may not see the same level of
disruption as software development. But remember what I just shared from that
CNBC article - that 11.7% wasn't just software development, it was the *entire*
U.S. labor market.

M.G. Siegler also writes:
> Wait. I should back up.
>
> As I'm suggesting above, as strange as it may seem, I actually haven't used AI to write something for me in my own style before.

This is when I realized where @mattshumer_'s article really was sounding the alarm: it's possible there isn't more panic because people aren't actually using these tools yet outside of software developers.

## Is it Cheating?

Earlier, I remarked that Claude sometimes feels like cheating. That's because
all I have to do is describe, in English, what I want, and Claude makes it so *in minutes*. Minor tweaks are often all that are required. 

This is striking to me because I'm a lifelong technologist. My entire career has
involved keeping myself educated on emerging technologies so I can learn how to
protect the organizations using them. I can't imagine what it will feel like for
someone, whether that's a new college grad or a 40-year veteran, to see their
entire (potential) livelihood get automated. Mine sure could!

I wonder, and worry, not that AI use is cheating, but whether *not* using it is viable. 

## Market Reaction

Perhaps @mattshumer_'s article *was* the alarm: the S&P 500 and the NASDAQ 100
slipped ~1.3% and ~2%, respectively from 2026-02-11 to 2026-02-12. Also last
week, when Anthropic announced Claude Cowork plugins, [nearly $1 trillion was
erased](https://fortune.com/2026/02/06/anthropic-claude-opus-4-6-stock-selloff-new-upgrade/)
from US firms. This week, the tongue-in-cheek term, "SaaSpocalypse" was thrown
around describing the market's reaction to this tooling, but as of this writing,
analysts are saying these fears were "overblown."

## Human Cost in the Gap

So what I'm getting at is this: what will be the human cost in the gap between
"pre-AI" and "most knowledge work is automated by AI"? M.G. Siegler admitted to
not having used Claude to write in his style. Most people haven't felt the
tremor yet. The scariest part of the future to me is that the landscape is in
upheaval before most realized there was an earthquake.
